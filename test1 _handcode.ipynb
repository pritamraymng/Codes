{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11457688,"sourceType":"datasetVersion","datasetId":7179142},{"sourceId":11457738,"sourceType":"datasetVersion","datasetId":7179176},{"sourceId":11457757,"sourceType":"datasetVersion","datasetId":7179191},{"sourceId":11457782,"sourceType":"datasetVersion","datasetId":7179212},{"sourceId":11482921,"sourceType":"datasetVersion","datasetId":7196948},{"sourceId":11695311,"sourceType":"datasetVersion","datasetId":7340529}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#finding the test accuracy\nimport os\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import DataLoader, random_split, Dataset\nfrom torch.utils.data import Subset\nimport wandb\nfrom PIL import Image\nfrom tabulate import tabulate\nimport numpy as np\nimport random\nimport shutil\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T05:59:44.559131Z","iopub.execute_input":"2025-05-06T05:59:44.559292Z","iopub.status.idle":"2025-05-06T05:59:57.524584Z","shell.execute_reply.started":"2025-05-06T05:59:44.559277Z","shell.execute_reply":"2025-05-06T05:59:57.523791Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"\n\n#  Load just color and texture\ncolor_df   = pd.read_csv('/kaggle/input/color-features/color_features_full.csv')\ntexture_df = pd.read_csv('/kaggle/input/texture-features/glcm_ngtdm_features_full.csv')\n\n#  Drop any “Class” column\nfor df in (color_df, texture_df):\n    if 'Class' in df.columns:\n        df.drop(columns=['Class'], inplace=True)\n\n#  Merge on Image_ID and set index\nfeatures_df = (\n    color_df\n    .merge(texture_df, on='Image_ID')\n    .set_index('Image_ID')\n)\n\n#  Collapse duplicates if any\nfeatures_df = features_df.groupby(level=0).first()\n\n#  Keep only numeric columns\nfeatures_df = features_df.select_dtypes(include=[np.number])\n\n# Record feature dimension\nfeature_dim = features_df.shape[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:00:29.350753Z","iopub.execute_input":"2025-05-06T06:00:29.351562Z","iopub.status.idle":"2025-05-06T06:00:29.788043Z","shell.execute_reply.started":"2025-05-06T06:00:29.351528Z","shell.execute_reply":"2025-05-06T06:00:29.787219Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"#  CUSTOM DATASET THAT RETURNS (img, tab_feats, label) \nclass SkinDataset(Dataset):\n    def __init__(self, root, transform, features_df):\n        self.folder   = datasets.ImageFolder(root=root, transform=transform)\n        self.features = features_df\n\n    def __len__(self):\n        return len(self.folder)\n\n    def __getitem__(self, idx):\n        # 1. load image+label\n        img, label = self.folder[idx]\n\n        # 2. extract Image_ID from the filepath\n        path, _   = self.folder.samples[idx]\n        image_id  = os.path.splitext(os.path.basename(path))[0]\n\n        # 3. look up and convert the numeric features\n        row = self.features.loc[image_id]              # pandas Series of floats/ints\n        tab = torch.tensor(row.values, dtype=torch.float32)\n\n        # 4. return the triplet\n        return img, tab, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:00:34.036352Z","iopub.execute_input":"2025-05-06T06:00:34.036612Z","iopub.status.idle":"2025-05-06T06:00:34.041900Z","shell.execute_reply.started":"2025-05-06T06:00:34.036594Z","shell.execute_reply":"2025-05-06T06:00:34.041249Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"#  TRANSFORMS & DATASET SPLITS \nIMG_SIZE = (224, 224)\ntransform_pipeline = transforms.Compose([\n    transforms.Resize(IMG_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n])\n\n# only for train+val\nimage_root      = '/kaggle/input/preprocessed-data/Optimized_output_final'\n# only for test\ntest_image_root = '/kaggle/input/test-new/test_new'\n\nrandom.seed(42)\n\n# Build full dataset over image_root\nfull_ds = SkinDataset(\n    root=image_root,\n    transform=transform_pipeline,\n    features_df=features_df\n)\ntotal      = len(full_ds)\n# 80-20 division\nn_test     = int(0.2 * total)\nn_trainval = total - n_test\nn_val      = int(0.1 * n_trainval)\nn_train    = n_trainval - n_val\n\n#Deterministic shuffle & take only train+val indices\nall_idxs = list(range(total))\nrandom.shuffle(all_idxs)\ntrain_idxs = all_idxs[:n_train]\nval_idxs   = all_idxs[n_train:n_train + n_val]\n\n#  Create in‑memory Subsets for train & val\ntrain_ds = Subset(full_ds, train_idxs)\nval_ds   = Subset(full_ds, val_idxs)\n\n#  Load fixed test split from disk\ntest_ds = SkinDataset(\n    root=test_image_root,\n    transform=transform_pipeline,\n    features_df=features_df\n)\n\n\n#  PRINT TEST‐SET CLASS COUNTS \nfrom tabulate import tabulate\n\nclass_counts = []\nfor cls in sorted(os.listdir(test_image_root)):\n    cls_dir = os.path.join(test_image_root, cls)\n    if not os.path.isdir(cls_dir):\n        continue\n    cnt = len([\n        f for f in os.listdir(cls_dir)\n        if f.lower().endswith(('.png','.jpg','.jpeg'))\n    ])\n    class_counts.append((cls, cnt))\n\nprint(tabulate(class_counts, headers=['Class', '# Test Images']))\ntotal_test = sum(count for _, count in class_counts)\nprint(f\"\\nTotal test images: {total_test}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:01:53.823187Z","iopub.execute_input":"2025-05-06T06:01:53.823461Z","iopub.status.idle":"2025-05-06T06:02:03.638563Z","shell.execute_reply.started":"2025-05-06T06:01:53.823441Z","shell.execute_reply":"2025-05-06T06:02:03.637950Z"}},"outputs":[{"name":"stdout","text":"Class                                                        # Test Images\n---------------------------------------------------------  ---------------\n1. Eczema                                                              335\n10. Warts Molluscum and other Viral Infections                         420\n2. Melanoma                                                            628\n3. Atopic Dermatitis                                                   251\n4. Basal Cell Carcinoma                                                664\n5. Melanocytic Nevi                                                   1594\n6. Benign Keratosis-like Lesions                                       415\n7. Psoriasis pictures Lichen Planus and related diseases               411\n8. Seborrheic Keratoses and other Benign Tumors                        369\n9. Tinea Ringworm Candidiasis and other Fungal Infections              340\n\nTotal test images: 5427\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Configure device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(\"Running on device:\", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:02:14.222235Z","iopub.execute_input":"2025-05-06T06:02:14.222880Z","iopub.status.idle":"2025-05-06T06:02:14.322755Z","shell.execute_reply.started":"2025-05-06T06:02:14.222847Z","shell.execute_reply":"2025-05-06T06:02:14.322026Z"}},"outputs":[{"name":"stdout","text":"Running on device: cuda\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def show_predictions_on_test(model, dataset, feature_dim, device='cuda'):\n    model.eval()\n    # get class names\n    classes = dataset.folder.classes\n\n    # pick 30 random samples\n    indices = random.sample(range(len(dataset)), 30)\n    imgs, tabs, trues, preds = [], [], [], []\n\n    # first collect images, tabs, true labels\n    for idx in indices:\n        img, tab, lbl = dataset[idx]\n        imgs.append(img)\n        tabs.append(tab)\n        trues.append(classes[lbl])\n\n    # then run predictions\n    with torch.no_grad():\n        for img, tab in zip(imgs, tabs):\n            img_b = img.unsqueeze(0).to(device)\n            tab_b = tab.unsqueeze(0).to(device)\n            out   = model(img_b, tab_b)\n            p     = out.argmax(dim=1).item()\n            preds.append(classes[p])\n\n    # plot 10×3 grid\n    fig, axes = plt.subplots(10, 3, figsize=(12, 30))\n    fig.suptitle(\"Test Data Predictions (Best Model)\", fontsize=16)\n\n    for ax, img, t, p in zip(axes.flat, imgs, trues, preds):\n        im = img.permute(1, 2, 0).cpu().numpy()\n        im = np.clip((im * 0.5) + 0.5, 0, 1)\n        ax.imshow(im)\n        ax.set_title(f\"True: {t}\\nPred: {p}\")\n        ax.axis(\"off\")\n\n    plt.tight_layout(rect=[0, 0, 1, 0.96])\n    wandb.log({\"Sample Predictions\": wandb.Image(fig)})\n    plt.close(fig)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:02:17.491867Z","iopub.execute_input":"2025-05-06T06:02:17.492401Z","iopub.status.idle":"2025-05-06T06:02:17.499292Z","shell.execute_reply.started":"2025-05-06T06:02:17.492380Z","shell.execute_reply":"2025-05-06T06:02:17.498613Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"#  EXTEND ResNet TO CONCAT TABULAR FEATURES\nclass ResNetWithTabular(nn.Module):\n    def __init__(self, base_model, tab_dim, num_classes=10):\n        super().__init__()\n        # everything except the final fc\n        self.backbone = nn.Sequential(*list(base_model.children())[:-1])  # output: [B,2048,1,1]\n        self.tab_bn   = nn.BatchNorm1d(tab_dim)\n        self.classifier = nn.Sequential(\n            nn.Flatten(),                          # flatten image feats\n            # image feature dim = base_model.fc.in_features\n            # + tabular dim\n            nn.Linear(base_model.fc.in_features + tab_dim, 512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(512, num_classes)\n        )\n\n    def forward(self, img, tab):\n        x = self.backbone(img)       # [B,2048,1,1]\n        x = torch.flatten(x, 1)      # [B,2048]\n        tab = self.tab_bn(tab)       # normalize tabular\n        x = torch.cat([x, tab], dim=1)\n        return self.classifier(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:02:21.966963Z","iopub.execute_input":"2025-05-06T06:02:21.967597Z","iopub.status.idle":"2025-05-06T06:02:21.972973Z","shell.execute_reply.started":"2025-05-06T06:02:21.967576Z","shell.execute_reply":"2025-05-06T06:02:21.972276Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"#  FINE‑TUNING CLASS \nclass FineTuneCNN:\n    def __init__(self, train_ds, valid_ds, base_model, batch_size=32, freeze_ratio=1.0, test_ds=None):\n        self.model = base_model\n        # freeze parameters\n        if freeze_ratio >= 1.0:\n            for p in self.model.parameters():\n                p.requires_grad = False\n        else:\n            total_p = sum(1 for _ in self.model.parameters())\n            to_freeze = int(total_p * freeze_ratio)\n            cnt = 0\n            for p in self.model.parameters():\n                p.requires_grad = False\n                cnt += 1\n                if cnt >= to_freeze:\n                    break\n        # ensure final layers are trainable\n        for p in self.model.classifier.parameters():\n            p.requires_grad = True\n\n        # override the default loaders\n        self.train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n        self.valid_loader = DataLoader(valid_ds, batch_size=batch_size, shuffle=False)\n        self.test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False) if test_ds else None\n\n    def run_training(self, num_epochs=10, learning_rate=1e-3, weight_decay_val=0):\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.model.to(device)\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.Adam(self.model.parameters(),\n                               lr=learning_rate,\n                               weight_decay=weight_decay_val)\n\n        for epoch in range(1, num_epochs+1):\n            # --- train ---\n            self.model.train()\n            running_correct = 0\n            running_total   = 0\n            for img, tab, lbl in self.train_loader:\n                img, tab, lbl = img.to(device), tab.to(device), lbl.to(device)\n                optimizer.zero_grad()\n                out = self.model(img, tab)\n                loss = criterion(out, lbl)\n                loss.backward()\n                optimizer.step()\n                pred = out.argmax(dim=1)\n                running_correct += (pred == lbl).sum().item()\n                running_total   += lbl.size(0)\n            train_acc = 100 * running_correct / running_total\n            print(f\"Epoch {epoch} — Train Acc: {train_acc:.2f}%\")\n            wandb.log({\"epoch\":epoch, \"train_acc\":train_acc})\n\n            # --- validate ---\n            self.model.eval()\n            val_corr = 0\n            val_tot  = 0\n            val_loss = 0.0\n            with torch.no_grad():\n                for img, tab, lbl in self.valid_loader:\n                    img, tab, lbl = img.to(device), tab.to(device), lbl.to(device)\n                    out = self.model(img, tab)\n                    l  = criterion(out, lbl)\n                    pred = out.argmax(dim=1)\n                    val_corr += (pred == lbl).sum().item()\n                    val_tot  += lbl.size(0)\n                    val_loss  = l.item()\n            val_acc = 100 * val_corr / val_tot\n            print(f\"Epoch {epoch} — Val   Acc: {val_acc:.2f}%\")\n            wandb.log({\"validation_accuracy\": val_acc, \"validation_loss\": val_loss})\n\n    def evaluate_test(self):\n        if self.test_loader is None:\n            print(\"No test set.\")\n            return\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.model.eval()\n        test_corr = 0\n        test_tot  = 0\n        with torch.no_grad():\n            for img, tab, lbl in self.test_loader:\n                img, tab, lbl = img.to(device), tab.to(device), lbl.to(device)\n                out = self.model(img, tab)\n                pred = out.argmax(dim=1)\n                test_corr += (pred == lbl).sum().item()\n                test_tot  += lbl.size(0)\n        test_acc = 100 * test_corr / test_tot\n        print(f\"Test Accuracy: {test_acc:.2f}%\")\n        wandb.log({\"test_accuracy\": test_acc})\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:02:26.031564Z","iopub.execute_input":"2025-05-06T06:02:26.031857Z","iopub.status.idle":"2025-05-06T06:02:26.044502Z","shell.execute_reply.started":"2025-05-06T06:02:26.031803Z","shell.execute_reply":"2025-05-06T06:02:26.043767Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import wandb\nimport numpy as np\nfrom types import SimpleNamespace\nimport random","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:02:32.201222Z","iopub.execute_input":"2025-05-06T06:02:32.201874Z","iopub.status.idle":"2025-05-06T06:02:32.204982Z","shell.execute_reply.started":"2025-05-06T06:02:32.201853Z","shell.execute_reply":"2025-05-06T06:02:32.204282Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"wandb.login(key='1df7a902fa4a610500b8e79e21818419d5facdbb')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:02:35.980643Z","iopub.execute_input":"2025-05-06T06:02:35.980928Z","iopub.status.idle":"2025-05-06T06:02:42.207056Z","shell.execute_reply.started":"2025-05-06T06:02:35.980907Z","shell.execute_reply":"2025-05-06T06:02:42.206489Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mma23m018\u001b[0m (\u001b[33mma23m018-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# BEST VALIDATION CONFIGS\nBEST_VAL_CONFIGS = [\n    {\n        'learning_rate': 1e-4,\n        'freeze_ratio':  0.2,\n        'l2_reg':        0,\n        'batch_size':    64,\n        'epochs':        10\n    }\n    \n\n]\n\n# SWEEP CONFIG TO MAXIMIZE test_accuracy\nsweep_config = {\n    'method':  'bayes',\n    'metric':  { 'name': 'test_accuracy', 'goal': 'maximize' },\n    'parameters': {\n        'config_idx': { 'values': list(range(len(BEST_VAL_CONFIGS))) }\n    }\n}\nsweep_id = wandb.sweep(sweep_config, entity= \"ma23m018-indian-institute-of-technology-madras\", project=\"mtech_project1_test2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:02:56.908290Z","iopub.execute_input":"2025-05-06T06:02:56.908699Z","iopub.status.idle":"2025-05-06T06:02:57.469054Z","shell.execute_reply.started":"2025-05-06T06:02:56.908678Z","shell.execute_reply":"2025-05-06T06:02:57.468464Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: jenasips\nSweep URL: https://wandb.ai/ma23m018-indian-institute-of-technology-madras/mtech_project1_test2/sweeps/jenasips\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"#sweep_id = wandb.sweep(sweep_config, entity= \"ma23m018-indian-institute-of-technology-madras\", project=\"mtech_project1_test1\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:08:58.405931Z","iopub.execute_input":"2025-04-20T18:08:58.406198Z","iopub.status.idle":"2025-04-20T18:08:58.884322Z","shell.execute_reply.started":"2025-04-20T18:08:58.406176Z","shell.execute_reply":"2025-04-20T18:08:58.883638Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: 7bxbulmu\nSweep URL: https://wandb.ai/ma23m018-indian-institute-of-technology-madras/mtech_project1_test1/sweeps/7bxbulmu\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"#\ndef main():\n    with wandb.init() as run:\n        idx = run.config.config_idx\n        cfg = BEST_VAL_CONFIGS[idx]\n        run.config.update(cfg, allow_val_change=False)\n        run.name = (f\"bs{cfg['batch_size']}\"\n                    f\"_ep{cfg['epochs']}\"\n                    f\"_lr{cfg['learning_rate']}\"\n                    f\"_fr{cfg['freeze_ratio']}\")\n\n        #rebuild model\n        base = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n        model = ResNetWithTabular(\n            base_model=base,\n            tab_dim=feature_dim,\n            num_classes=10\n        )\n\n        #initialize finetuner *with* the test set\n        finetuner = FineTuneCNN(\n            train_ds=train_ds,     # from  existing train/val split\n            valid_ds=val_ds,\n            base_model=model,\n            batch_size=cfg['batch_size'],\n            freeze_ratio=cfg['freeze_ratio'],\n            test_ds=test_ds       \n        )\n\n        #train+validate, then evaluate on test\n        finetuner.run_training(\n            num_epochs=cfg['epochs'],\n            learning_rate=cfg['learning_rate'],\n            weight_decay_val=cfg['l2_reg']\n        )\n        finetuner.evaluate_test()\n        show_predictions_on_test(\n        model=finetuner.model,\n         dataset=test_ds,\n         feature_dim=feature_dim,\n         device=device)\n\n\n#  SWEEP \nwandb.agent(sweep_id, function=main, count=len(BEST_VAL_CONFIGS))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:03:03.764708Z","iopub.execute_input":"2025-05-06T06:03:03.765377Z","iopub.status.idle":"2025-05-06T06:48:32.660986Z","shell.execute_reply.started":"2025-05-06T06:03:03.765353Z","shell.execute_reply":"2025-05-06T06:48:32.660366Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8sfldfcc with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tconfig_idx: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250506_060310-8sfldfcc</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23m018-indian-institute-of-technology-madras/mtech_project1_test2/runs/8sfldfcc' target=\"_blank\">fearless-sweep-1</a></strong> to <a href='https://wandb.ai/ma23m018-indian-institute-of-technology-madras/mtech_project1_test2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23m018-indian-institute-of-technology-madras/mtech_project1_test2/sweeps/jenasips' target=\"_blank\">https://wandb.ai/ma23m018-indian-institute-of-technology-madras/mtech_project1_test2/sweeps/jenasips</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23m018-indian-institute-of-technology-madras/mtech_project1_test2' target=\"_blank\">https://wandb.ai/ma23m018-indian-institute-of-technology-madras/mtech_project1_test2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23m018-indian-institute-of-technology-madras/mtech_project1_test2/sweeps/jenasips' target=\"_blank\">https://wandb.ai/ma23m018-indian-institute-of-technology-madras/mtech_project1_test2/sweeps/jenasips</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23m018-indian-institute-of-technology-madras/mtech_project1_test2/runs/8sfldfcc' target=\"_blank\">https://wandb.ai/ma23m018-indian-institute-of-technology-madras/mtech_project1_test2/runs/8sfldfcc</a>"},"metadata":{}},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 198MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 — Train Acc: 59.31%\nEpoch 1 — Val   Acc: 67.45%\nEpoch 2 — Train Acc: 70.97%\nEpoch 2 — Val   Acc: 69.11%\nEpoch 3 — Train Acc: 78.50%\nEpoch 3 — Val   Acc: 69.38%\nEpoch 4 — Train Acc: 85.89%\nEpoch 4 — Val   Acc: 73.48%\nEpoch 5 — Train Acc: 91.48%\nEpoch 5 — Val   Acc: 70.86%\nEpoch 6 — Train Acc: 94.70%\nEpoch 6 — Val   Acc: 70.49%\nEpoch 7 — Train Acc: 96.08%\nEpoch 7 — Val   Acc: 70.76%\nEpoch 8 — Train Acc: 97.07%\nEpoch 8 — Val   Acc: 70.07%\nEpoch 9 — Train Acc: 96.98%\nEpoch 9 — Val   Acc: 71.04%\nEpoch 10 — Train Acc: 97.43%\nEpoch 10 — Val   Acc: 70.72%\nTest Accuracy: 90.55%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>train_acc</td><td>▁▃▅▆▇▇████</td></tr><tr><td>validation_accuracy</td><td>▁▃▃█▅▅▅▄▅▅</td></tr><tr><td>validation_loss</td><td>▂▂▃▂▁▆█▅▂▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_accuracy</td><td>90.54726</td></tr><tr><td>train_acc</td><td>97.42724</td></tr><tr><td>validation_accuracy</td><td>70.71823</td></tr><tr><td>validation_loss</td><td>1.00704</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">bs64_ep10_lr0.0001_fr0.2</strong> at: <a href='https://wandb.ai/ma23m018-indian-institute-of-technology-madras/mtech_project1_test2/runs/8sfldfcc' target=\"_blank\">https://wandb.ai/ma23m018-indian-institute-of-technology-madras/mtech_project1_test2/runs/8sfldfcc</a><br> View project at: <a href='https://wandb.ai/ma23m018-indian-institute-of-technology-madras/mtech_project1_test2' target=\"_blank\">https://wandb.ai/ma23m018-indian-institute-of-technology-madras/mtech_project1_test2</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250506_060310-8sfldfcc/logs</code>"},"metadata":{}}],"execution_count":13}]}