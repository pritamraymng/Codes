{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aebb85d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image count per class:\n",
      "------------------------------\n",
      "Class Name               Count\n",
      "------------------------------\n",
      "1. Eczema 1677            1677\n",
      "10. Warts Molluscum and other Viral Infections - 2103      2103\n",
      "2. Melanoma 15.75k        3140\n",
      "3. Atopic Dermatitis - 1.25k      1257\n",
      "4. Basal Cell Carcinoma (BCC) 3323      3323\n",
      "5. Melanocytic Nevi (NV) - 7970      7970\n",
      "6. Benign Keratosis-like Lesions (BKL) 2624      2079\n",
      "7. Psoriasis pictures Lichen Planus and related diseases - 2k      2055\n",
      "8. Seborrheic Keratoses and other Benign Tumors - 1.8k      1847\n",
      "9. Tinea Ringworm Candidiasis and other Fungal Infections - 1.7k      1702\n",
      "------------------------------\n",
      "Total images:            27153\n",
      "Processing images in 1. Eczema 1677\n",
      "Processing images in 10. Warts Molluscum and other Viral Infections - 2103\n",
      "Processing images in 2. Melanoma 15.75k\n",
      "Processing images in 3. Atopic Dermatitis - 1.25k\n",
      "Processing images in 4. Basal Cell Carcinoma (BCC) 3323\n",
      "Processing images in 5. Melanocytic Nevi (NV) - 7970\n",
      "Processing images in 6. Benign Keratosis-like Lesions (BKL) 2624\n",
      "Processing images in 7. Psoriasis pictures Lichen Planus and related diseases - 2k\n",
      "Processing images in 8. Seborrheic Keratoses and other Benign Tumors - 1.8k\n",
      "Processing images in 9. Tinea Ringworm Candidiasis and other Fungal Infections - 1.7k\n",
      "\n",
      "Processing complete. Noise removed images saved in 'Optimized_output_final' folder.\n"
     ]
    }
   ],
   "source": [
    "#noise removal process code\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def kapur_entropy_thresholding(image):\n",
    "    hist = cv2.calcHist([image], [0], None, [256], [0, 256]).flatten()\n",
    "    total_pixels = np.sum(hist)\n",
    "    probabilities = hist / total_pixels\n",
    "    max_entropy = -np.inf\n",
    "    optimal_threshold = 0\n",
    "\n",
    "    for t in range(1, 256):\n",
    "        P1 = np.sum(probabilities[:t])\n",
    "        if P1 == 0:\n",
    "            continue\n",
    "        H1 = -np.sum((probabilities[:t] / P1) * np.log(probabilities[:t] / P1 + 1e-10))\n",
    "\n",
    "        P2 = np.sum(probabilities[t:])\n",
    "        if P2 == 0:\n",
    "            continue\n",
    "        H2 = -np.sum((probabilities[t:] / P2) * np.log(probabilities[t:] / P2 + 1e-10))\n",
    "\n",
    "        total_entropy = H1 + H2\n",
    "\n",
    "        if total_entropy > max_entropy:\n",
    "            max_entropy = total_entropy\n",
    "            optimal_threshold = t\n",
    "\n",
    "    return optimal_threshold\n",
    "\n",
    "def create_lesion_mask(image, adaptive_threshold):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_gray = clahe.apply(gray)\n",
    "    blurred = cv2.medianBlur(enhanced_gray, 5)\n",
    "\n",
    "    sobelx = cv2.Sobel(blurred, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobely = cv2.Sobel(blurred, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    gradient_magnitude = np.sqrt(sobelx ** 2 + sobely ** 2)\n",
    "\n",
    "    # Calculate the average of gradient_magnitude as the threshold\n",
    "    sobel_threshold = np.mean(gradient_magnitude)\n",
    "\n",
    "    # Create edge mask based on the average threshold\n",
    "    edge_mask = np.zeros_like(gray, dtype=np.uint8)\n",
    "    edge_mask[gradient_magnitude > sobel_threshold] = 255\n",
    "\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    a_channel = lab[:, :, 1]\n",
    "    mean_a = np.mean(a_channel)\n",
    "    is_red_dominant = mean_a > 128\n",
    "\n",
    "    mask = np.zeros_like(blurred)\n",
    "    if is_red_dominant:\n",
    "        mask[a_channel > mean_a] = 255\n",
    "    else:\n",
    "        mask[blurred <= adaptive_threshold] = 255\n",
    "\n",
    "    mask = cv2.bitwise_or(mask, edge_mask)\n",
    "\n",
    "    kernel_size = max(5, image.shape[0] // 100)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    min_area = image.shape[0] * image.shape[1] * 0.01\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) < min_area:\n",
    "            cv2.drawContours(mask, [contour], -1, 0, -1)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def segment_lesion(image, mask):\n",
    "    segmented = np.zeros_like(image)\n",
    "    segmented[mask == 255] = image[mask == 255]\n",
    "    return segmented\n",
    "\n",
    "# Updated noise removal function for efficient and accurate noise pixel replacement\n",
    "def remove_noise(image, mask):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply black top-hat transform\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (17, 3))\n",
    "    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)\n",
    "\n",
    "    # Threshold the black top-hat result to create a noise mask\n",
    "    _, noise_mask = cv2.threshold(blackhat, 10, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Restrict noise to lesion region\n",
    "    noise_mask = cv2.bitwise_and(noise_mask, mask)\n",
    "\n",
    "    # Calculate the percentage of noisy pixels\n",
    "    noise_percentage = (np.sum(noise_mask) / 255) / np.sum(mask / 255) * 100\n",
    "\n",
    "    # If noise percentage is below a threshold, return the original image\n",
    "    if noise_percentage < 1.0:  # You can adjust this threshold as needed\n",
    "        return image\n",
    "\n",
    "    # If noise is detected, proceed with noise removal as before\n",
    "    result = image.copy()\n",
    "    filtered_image = cv2.bilateralFilter(image, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "    noise_coords = np.column_stack(np.where(noise_mask == 255))\n",
    "    directions = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n",
    "\n",
    "    for y, x in noise_coords:\n",
    "        valid_neighbors = []\n",
    "        search_radius = 1\n",
    "        \n",
    "        while not valid_neighbors:\n",
    "            for dy in range(-search_radius, search_radius + 1):\n",
    "                for dx in range(-search_radius, search_radius + 1):\n",
    "                    ny, nx = y + dy, x + dx\n",
    "                    if 0 <= ny < image.shape[0] and 0 <= nx < image.shape[1] and mask[ny, nx] == 255 and noise_mask[ny, nx] == 0:\n",
    "                        valid_neighbors.append(filtered_image[ny, nx])\n",
    "            \n",
    "            if not valid_neighbors:\n",
    "                search_radius += 1\n",
    "        \n",
    "        result[y, x] = np.mean(valid_neighbors, axis=0).astype(np.uint8)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def process_image(image_path, output_folder, class_name):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (150, 150))\n",
    "\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    hist_normalized = cv2.calcHist([gray_image], [0], None, [256], [0, 256]).flatten() / gray_image.size\n",
    "\n",
    "    max_sigma, otsu_threshold = 0, 0\n",
    "    for T in range(1, 256):\n",
    "        P1, P2 = hist_normalized[:T].sum(), hist_normalized[T:].sum()\n",
    "        if P1 == 0 or P2 == 0:\n",
    "            continue\n",
    "        mu1 = np.dot(np.arange(T), hist_normalized[:T]) / P1\n",
    "        mu2 = np.dot(np.arange(T, 256), hist_normalized[T:]) / P2\n",
    "        sigma_b_squared = P1 * P2 * (mu1 - mu2) ** 2\n",
    "        if sigma_b_squared > max_sigma:\n",
    "            max_sigma, otsu_threshold = sigma_b_squared, T\n",
    "\n",
    "    kapur_threshold = kapur_entropy_thresholding(gray_image)\n",
    "    image_entropy = -np.sum(hist_normalized * np.log(hist_normalized + 1e-10))\n",
    "    w_kapur = image_entropy / (image_entropy + max_sigma)\n",
    "    w_otsu = max_sigma / (image_entropy + max_sigma)\n",
    "    adaptive_threshold = int(w_kapur * kapur_threshold + w_otsu * otsu_threshold)\n",
    "\n",
    "    mask = create_lesion_mask(image, adaptive_threshold)\n",
    "    segmented = segment_lesion(image, mask)\n",
    "    noise_removed = remove_noise(segmented, mask)\n",
    "\n",
    "    class_output_folder = os.path.join(output_folder, class_name)\n",
    "    os.makedirs(class_output_folder, exist_ok=True)\n",
    "\n",
    "    noise_removed_path = os.path.join(class_output_folder, f\"noise_removed_{os.path.basename(image_path)}\")\n",
    "    cv2.imwrite(noise_removed_path, noise_removed)\n",
    "\n",
    "def process_all_images(input_folder):\n",
    "    output_folder = os.path.join(os.path.dirname(input_folder), \"Optimized_output_final\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    class_counts = {}\n",
    "    total_images = 0\n",
    "\n",
    "    for class_name in os.listdir(input_folder):\n",
    "        class_path = os.path.join(input_folder, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            image_count = len([f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "            class_counts[class_name] = image_count\n",
    "            total_images += image_count\n",
    "\n",
    "    print(\"\\nImage count per class:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"{'Class Name':<20}{'Count':>10}\")\n",
    "    print(\"-\" * 30)\n",
    "    for class_name, count in class_counts.items():\n",
    "        print(f\"{class_name:<20}{count:>10}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"{'Total images:':<20}{total_images:>10}\")\n",
    "\n",
    "\n",
    "    for class_name in os.listdir(input_folder):\n",
    "        class_path = os.path.join(input_folder, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            print(f\"Processing images in {class_name}\")\n",
    "            for image_name in os.listdir(class_path):\n",
    "                if image_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    image_path = os.path.join(class_path, image_name)\n",
    "                    process_image(image_path, output_folder, class_name)\n",
    "\n",
    "    print(\"\\nProcessing complete. Noise removed images saved in 'Optimized_output_final' folder.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = \"F:\\IMG_CLASSES\"\n",
    "    process_all_images(input_folder)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0489e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
